# ğŸ¤– RAG QA PDF

Há»‡ thá»‘ng há»i Ä‘Ã¡p thÃ´ng minh vá»›i tÃ i liá»‡u PDF sá»­ dá»¥ng RAG (Retrieval-Augmented Generation) vÃ  AI

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- ğŸ“„ **Upload & Xá»­ lÃ½ PDF**: Táº£i lÃªn vÃ  phÃ¢n tÃ­ch tÃ i liá»‡u PDF tá»± Ä‘á»™ng
- ğŸ’¬ **Chat thÃ´ng minh**: Äáº·t cÃ¢u há»i vÃ  nháº­n tráº£ lá»i dá»±a trÃªn ná»™i dung tÃ i liá»‡u
- ğŸ‡»ğŸ‡³ **Há»— trá»£ tiáº¿ng Viá»‡t**: Tá»‘i Æ°u cho ngÃ´n ngá»¯ tiáº¿ng Viá»‡t vá»›i Vietnamese-bi-encoder
- ğŸŒ **Cháº¡y trÃªn Google Colab**: Sá»­ dá»¥ng GPU miá»…n phÃ­ vá»›i ngrok tunnel
- ğŸ” **Semantic Search**: TÃ¬m kiáº¿m ngá»¯ nghÄ©a chÃ­nh xÃ¡c vá»›i ChromaDB
- âš¡ **4-bit Quantization**: Tá»‘i Æ°u bá»™ nhá»› vá»›i BitsAndBytesConfig

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
ğŸ“„ PDF Input â†’ ğŸ”„ Document Loader â†’ âœ‚ï¸ Semantic Splitter â†’ ğŸ—„ï¸ Vector Store â†’ ğŸ” Retriever
                                                                                    â†“
ğŸ¤– LLM Response â† ğŸ“ Prompt Template â† ğŸ”— RAG Chain â† ğŸ¯ Context + Question â†â”€â”€â”€â”€â”˜
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### PhÆ°Æ¡ng phÃ¡p 1: Google Colab (Khuyáº¿n nghá»‹)

1. **Láº¥y Ngrok Authtoken**:
   ```
   - ÄÄƒng kÃ½ táº¡i: https://dashboard.ngrok.com/signup
   - Copy authtoken tá»« dashboard
   ```

2. **Cáº­p nháº­t file .env**:
   ```env
   MODEL_NAME=microsoft/DialoGPT-medium
   NGROK_AUTHTOKEN=your_authtoken_here
   ```

3. **Cháº¡y trÃªn Colab**:
   ```python
   # Upload project files lÃªn Colab
   !python run_ngrok.py
   ```

4. **Sá»­ dá»¥ng**:
   - Click vÃ o public URL tá»« ngrok
   - Upload file PDF qua giao diá»‡n
   - Báº¯t Ä‘áº§u chat vá»›i tÃ i liá»‡u!

### PhÆ°Æ¡ng phÃ¡p 2: MÃ¡y local

```bash
# Clone repository
git clone <repository-url>
cd RAG_QA_PDF

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Cháº¡y á»©ng dá»¥ng
streamlit run main.py
```

## ğŸ“ Cáº¥u trÃºc project

```
RAG_QA_PDF/
â”œâ”€â”€ main.py                    # á»¨ng dá»¥ng Streamlit chÃ­nh
â”œâ”€â”€ run_ngrok.py              # Script cháº¡y trÃªn Google Colab vá»›i ngrok
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ .env                      # Cáº¥u hÃ¬nh (MODEL_NAME, NGROK_AUTHTOKEN)
â”œâ”€â”€ create_logo.py           # Script táº¡o logo (optional)
â”œâ”€â”€ data/                    # ThÆ° má»¥c chá»©a PDF files
â”œâ”€â”€ src/                     # Source code chÃ­nh
â”‚   â”œâ”€â”€ llm.py              # Language Model vá»›i quantization
â”‚   â”œâ”€â”€ loader.py           # PDF Document Loader
â”‚   â””â”€â”€ semantic_splitter.py # Semantic Document Splitter
â”œâ”€â”€ model_embedding/         # Embedding models
â”‚   â””â”€â”€ model.py            # Vietnamese & multilingual embeddings
â””â”€â”€ vectordb/               # Vector database
    â””â”€â”€ chroma.py           # ChromaDB implementation
```

## ğŸ”§ Cáº¥u hÃ¬nh chi tiáº¿t

### Models Ä‘Æ°á»£c há»— trá»£

**Language Models:**
- `microsoft/DialoGPT-medium` (khuyáº¿n nghá»‹ cho Colab - ~1.5GB)
- `microsoft/DialoGPT-small` (backup model - ~500MB)
- `lmsys/vicuna-7b-v1.5` (cháº¥t lÆ°á»£ng cao - ~13GB RAM)

**Embedding Models:**
- `bkai-foundation-models/vietnamese-bi-encoder` (chÃ­nh - tiáº¿ng Viá»‡t)
- `all-MiniLM-L6-v2` (backup - Ä‘a ngÃ´n ngá»¯)

### File .env

```env
# Language Model (chá»n 1 trong cÃ¡c options trÃªn)
MODEL_NAME=microsoft/DialoGPT-medium

# Ngrok Authtoken (láº¥y tá»« https://dashboard.ngrok.com/)
NGROK_AUTHTOKEN=your_actual_authtoken_here
```

### Dependencies chÃ­nh

```
transformers==4.52.4          # Hugging Face Transformers
bitsandbytes==0.46.0          # 4-bit quantization
langchain==0.3.25             # RAG framework
langchain-chroma==0.2.4       # ChromaDB integration
streamlit                     # Web interface
pypdf                         # PDF processing
torch                         # PyTorch backend
```

## ğŸ¯ Workflow hoáº¡t Ä‘á»™ng

1. **Model Loading**: Táº£i embedding model vÃ  LLM vá»›i quantization
2. **PDF Processing**: Upload â†’ PyPDFLoader â†’ Semantic splitting
3. **Vector Storage**: Embedding documents â†’ ChromaDB â†’ Retriever
4. **RAG Chain**: Question â†’ Retrieval â†’ Context + Prompt â†’ LLM â†’ Answer
5. **Chat Interface**: Streamlit UI vá»›i chat history vÃ  controls

## â“ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

**ğŸ”´ Ngrok authtoken khÃ´ng há»£p lá»‡**
```
âŒ NGROK_AUTHTOKEN not found in .env file!
```
**Giáº£i phÃ¡p**: ÄÄƒng kÃ½ ngrok.com vÃ  thÃªm authtoken vÃ o .env

**ğŸ”´ Out of Memory**
```
âŒ CUDA out of memory
```
**Giáº£i phÃ¡p**: 
- DÃ¹ng model nhá» hÆ¡n: `MODEL_NAME=microsoft/DialoGPT-small`
- Restart Colab runtime
- Sá»­ dá»¥ng High-RAM runtime (Colab Pro)

**ğŸ”´ Model loading failed**
```
âŒ Error loading LLM: Connection timeout
```
**Giáº£i phÃ¡p**:
- Kiá»ƒm tra káº¿t ná»‘i internet
- Thá»­ model backup tá»± Ä‘á»™ng
- Clear Hugging Face cache: `!rm -rf ~/.cache/huggingface/`

**ğŸ”´ SemanticChunker error**
```
âŒ SemanticChunker model_embedding error
```
**Giáº£i phÃ¡p**: ÄÃ£ fix trong code vá»›i fallback mechanism

### Performance Tips

- ğŸ”‹ **GPU Runtime**: Sá»­ dá»¥ng GPU T4 trÃªn Colab
- ğŸ“ **CÃ¢u há»i cá»¥ thá»ƒ**: Äáº·t cÃ¢u há»i rÃµ rÃ ng Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t
- â° **KiÃªn nháº«n**: Model loading láº§n Ä‘áº§u máº¥t 5-10 phÃºt
- ğŸ”„ **Restart**: Restart runtime náº¿u gáº·p memory issues

## ğŸŒŸ TÃ­nh nÄƒng nÃ¢ng cao

### Semantic Splitting
- Sá»­ dá»¥ng `SemanticChunker` thay vÃ¬ split cá»‘ Ä‘á»‹nh
- Tá»± Ä‘á»™ng phÃ¡t hiá»‡n ranh giá»›i ngá»¯ nghÄ©a
- Chunk size linh hoáº¡t: 500-1500 tokens

### Smart Fallbacks
- Tá»± Ä‘á»™ng chuyá»ƒn sang backup model náº¿u main model fail
- Fallback prompt template náº¿u hub.pull() fail
- Error handling toÃ n diá»‡n

### Optimizations
- 4-bit quantization giáº£m 75% memory usage
- Streamlit caching cho models
- Efficient vector retrieval vá»›i ChromaDB

## ğŸ“ Há»— trá»£

- ğŸ“– **Setup chi tiáº¿t**: Äá»c file `run_ngrok.py` comments
- ğŸ› **Bug reports**: Táº¡o issue vá»›i error logs
- ğŸ’¬ **Questions**: LiÃªn há»‡ team development
- ğŸ”§ **Customization**: Modify models trong .env file

## ğŸ‘¥ Contributors

- Trinh Nam Thuan
- Tráº§n VÄƒn Máº¡nh

## ğŸ“Š Benchmark

| Component | Model | Size | Speed | Accuracy |
|-----------|-------|------|-------|----------|
| Embedding | vietnamese-bi-encoder | ~400MB | Fast | High (VN) |
| LLM | DialoGPT-medium | ~1.5GB | Medium | Good |
| Vector DB | ChromaDB | Variable | Fast | High |
| Total RAM | - | ~4-6GB | - | - |

---

**ğŸ‰ ChÃºc báº¡n sá»­ dá»¥ng thÃ nh cÃ´ng RAG QA PDF!**

*Developed with â¤ï¸ for Vietnamese AI community*